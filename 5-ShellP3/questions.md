1. Your shell forks multiple child processes when executing piped commands. How does your implementation ensure that all child processes complete before the shell continues accepting user input? What would happen if you forgot to call waitpid() on all child processes?

In my implementation, waitpid() is called for each child process in the execute_pipeline() function to ensure that the shell waits for all child processes to complete before accepting new user input. waitpid() blocks the parent process until the specific child process has finished, ensuring that the shell doesn't move on to process new input until the command execution is fully completed. If waitpid() is not called, the child processes could remain running in the background. This would lead to a process that have completed execution but are still listed in the process table, consuming system resources. Without waiting for the child processes, the shell would potentially move on to the next user input while commands are still being executed, leading to unexpected behavior.

2. The dup2() function is used to redirect input and output file descriptors. Explain why it is necessary to close unused pipe ends after calling dup2(). What could go wrong if you leave pipes open?

The dup2() function is used to duplicate file descriptors, redirecting the input/output to a pipe, file, or another descriptor. After calling dup2(), the child process has successfully redirected its input or output to the appropriate pipe ends. It is necessary to close unused pipe ends because if you leave the unused pipe ends open, it could result in a stand off behavior. Like in the case of a pipe between two processes, if one process doesn't close its end of the pipe after dup2(), the other process might not receive the correct data, or the pipe might remain open indefinitely. It ensures that the file descriptor used for dup2() is the only one writing or reading to the pipe, avoiding issues with unintended data flow or resource leakage. If you forget to close unused pipe ends, the shell could run into problems like a stand off behavior, where processes are waiting on each other to close pipes, incorrect output, or memory/resource leaks.

3. Your shell recognizes built-in commands (cd, exit, dragon). Unlike external commands, built-in commands do not require execvp(). Why is cd implemented as a built-in rather than an external command? What challenges would arise if cd were implemented as an external process?

The cd command is implemented as a built-in command rather than an external command because it affects the shell's current working directory, and this change should persist within the same shell session. If cd were implemented as an external command, the child process running the command would change its own working directory, but the parent shell (the one you are interacting with) would not be affected. After the child process exits, the working directory would revert to the original directory, making it impossible for the user to change the shell's current directory effectively. Some challenges of implementing cd as an external command is the working directory change would be local to the child process, and wouldn't affect the shell that spawned it. This would require a more complicated system to manage the state of the working directory, which would defeat the purpose of having a simple built-in command.

4. Currently, your shell supports a fixed number of piped commands (CMD_MAX). How would you modify your implementation to allow an arbitrary number of piped commands while still handling memory allocation efficiently? What trade-offs would you need to consider?

To allow an arbitrary number of piped commands, you would dynamically allocate memory for pipes and process IDs using malloc(). Instead of a fixed-size array, you can allocate memory based on the number of commands 
(int **pipes = malloc(sizeof(int*) * (num_cmds - 1)); and pid_t *pids = malloc(sizeof(pid_t) * num_cmds);). 
Some tradeoffs is memory efficiency. Dynamic allocation avoids fixed buffer sizes but requires careful memory management. As well as complexity, it adds complexity since you need to handle memory allocation and deallocation. And performance, the overhead of dynamic allocation is minimal unless handling a very large number of commands rapidly. This approach allows flexible piped command handling without a fixed limit.
